{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Project\n",
    "\n",
    "La industria de la restauración esta más dura que nunca, con críticas en Internet desde el primer día de la apertura de un restaurante. Pero como amante de la comida, usted y su amigo deciden entrar en la industria y abrir su propio restaurante, Danielle's Delicious Delicacies. Dado que el éxito de un restaurante está altamente correlacionado con su reputación, usted quiere asegurarse de que Danielle's Delicious Delicacies tenga las mejores críticas en el sitio de reseñas de restaurantes más consultado: Yelp! \n",
    "\n",
    "Aunque usted sabe que su comida será deliciosa, cree que hay otros factores que influyen en la calificación de Yelp y que, en última instancia, determinarán el éxito de su negocio. Con un conjunto de datos de diferentes características del restaurante y sus clasificaciones Yelp, usted decide usar un modelo de Regresión Lineal Múltiple para investigar qué factores afectan más la clasificación Yelp de un restaurante y predecir la clasificación Yelp para su restaurante.\n",
    "\n",
    "En este proyecto trabajaremos con un conjunto de datos reales proporcionados por Yelp. Hemos proporcionado seis archivos, que se enumeran a continuación con una breve descripción:\n",
    "\n",
    "`yelp_business.json`: datos del establecimiento relativos a la ubicación y los atributos de todas las empresas en el conjunto de datos\n",
    "`yelp_review.json`: metadatos de las calificaciones por empresa\n",
    "`yelp_user.json`: metadatos del perfil de usuario por empresa\n",
    "`yelp_checkin.json`: metadatos de facturación online por empresa\n",
    "`yelp_tip.json`: metadatos de consejos por empresa\n",
    "`yelp_photo.json`: metadatos de fotos por empresa\n",
    "\n",
    "Nota: como puede ver los datos estan en `.json`, un formato diferente a `.csv`, pero no te preocupes, es lo mismo al momento de importarlos y trabajarlos, aqui te vamos a ir enseñando como, sigue adelante!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos y echar un vistazo\n",
    "Para obtener una mejor comprensión del conjunto de datos podemos usar Pandas para explorar los datos en forma de DataFrame. En el siguiente bloque de código debes importar Pandas. El método `read_json()` lee los datos de un archivo json en un DataFrame, como se muestra a continuación:\n",
    "\n",
    "`df = pd.read_json('file_name.json', lines=True)`\n",
    "\n",
    "Cargue los datos de cada uno de los archivos json con las siguientes convenciones para fijar nombres:\n",
    "\n",
    "`yelp_business.json` en un DataFrame llamado `business`\n",
    "\n",
    "`yelp_review.json` en un DataFrame llamado `reviews`\n",
    "\n",
    "`yelp_user.json` en un DataFrame nombrando `users`\n",
    "\n",
    "`yelp_checkin.json` en un DataFrame llamado `checkins`\n",
    "\n",
    "`yelp_tip.json` en un DataFrame llamado `tips`\n",
    "\n",
    "`yelp_photo.json` en un DataFrame llamado `photos`\n",
    "\n",
    "La importación de esos datos puede tardar de 10 a 20 segundos en ejecutarse dependiendo de su computadora, pero no se preocupe, una vez cargados, ¡ya está listo para empezar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ver más claramente la información en nuestro DataFrame, podemos ajustar el número de columnas mostradas (`max_columns`) y el número de caracteres mostrados en una columna (`max_colwidth`) con el siguiente código:\n",
    "\n",
    "```\n",
    "pd.options.display.max_columns = number_of_columns_to_display\n",
    "pd.options.display.max_colwidth = number_of_characters_to_display\n",
    "```\n",
    "\n",
    "Ajuste `max_columns` a `60` y `max_colwidth` a `500`. Estamos trabajando con algunos datos GRANDES aquí! (bienvenido al Big Data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccione las primeras cinco filas de cada DataFrame usando el método `.head()` para obtener una visión general de los datos (asegúrese de revisar cada DataFrame en una celda separada para poder verlo correctamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántos negocios diferentes hay en el conjunto de datos? ¿Cuáles son las diferentes características/features/columnas en el DataFrame `reviews`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es el rango de valores para las features del DataFrame `users`? Nota: puedes usar el metodo `.describe()` para hacer esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la calificación Yelp, o estrellas, del establecimiento con `business_id=5EvUIR4IzCWWUOOm0PsUZXjA` Utilice la indexación booleana de Pandas para encontrar la clasificación de Yelp, usando la sintaxis de abajo:\n",
    "\n",
    "```\n",
    "df[df['column_we_know'] == 'value_we_know']['column_we_want']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusionar los datos\n",
    "Como estamos trabajando con datos de varios archivos, necesitamos combinar los datos en un solo DataFrame que nos permita analizar las diferentes características con respecto a nuestra variable objetivo, la clasificación Yelp. \n",
    "\n",
    "Podemos hacer esto fusionando los múltiples DataFrames que tenemos juntos, uniéndolos en las columnas que tienen en común. En nuestro caso, esta columna de identificación única es el `business_id`. \n",
    "\n",
    "Dados nuestros seis DataFrames, necesitaremos realizar 5 fusiones para combinar todos los datos en un solo DataFrame. Fusione primero `business` y `reviews` con un `left join` y asignelo a una variable llamada `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine cada uno de los otros 4 DataFrames en nuestro nuevo DataFrame `df` para combinar todos los datos juntos. Asegúrese de que `df` es el DataFrame izquierdo en cada fusión y que hace `left join` en cada uno de ellos ya que no todos los DataFrame incluyen todos los negocios en el conjunto de datos (de esta manera no perderemos ningún dato durante las fusiones). Una vez combinada, imprima las columnas de `df`. ¿Qué características/features/columnas tiene este nuevo DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos\n",
    "Nos estamos acercando mucho a la parte del análisis divertido! Sólo tenemos que limpiar un poco nuestros datos para que podamos centrarnos en las características que podrían tener poder predictivo para determinar la calificación Yelp de un establecimiento.\n",
    "\n",
    "En un modelo de Regresión Lineal, nuestras características serán idealmente variables continuas que afectan a nuestra variable dependiente, o sea la clasificación de Yelp. Para este proyecto también se trabajará con algunas características que son binarias, en la escala `[0,1]`. Con esta información, podemos eliminar cualquier columna en el conjunto de datos que no sea continua o binaria, y sobre la que no queramos hacer predicciones. La siguiente celda contiene una lista de estas características innecesarias. Sáquelos de `df` con la sintaxis de `drop` de Pandas, basicamente necesitamos remover las siguientes columnas:\n",
    "\n",
    "```\n",
    "'address',\n",
    "'attributes',\n",
    "'business_id',\n",
    "'categories',\n",
    "'city',\n",
    "'hours',\n",
    "'is_open',\n",
    "'latitude',\n",
    "'longitude',\n",
    "'name',\n",
    "'neighborhood',\n",
    "'postal_code',\n",
    "'state',\n",
    "'time'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sólo tenemos que comprobar nuestros datos para asegurarnos de que no nos faltan valores, o `NaNs`, lo que impedirá que el modelo de Regresión Lineal funcione correctamente. Para ello podemos utilizar la sentencia `df.isna().any()`. Esto comprobará todas nuestras columnas y devolverá `True` si hay valores faltantes o `NaNs`, o `False` si no hay valores faltantes. Compruebe si a `df` le falta algún valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, hay algunas columnas con valores que faltan. Dado que nuestro conjunto de datos no tiene información registrada para algunos negocios en estas columnas, asumiremos que las páginas de Yelp no muestran estas características. Por ejemplo, si hay un valor `NaN` para `number_pics`, significa que el negocio asociado no tenía ninguna imagen publicada en su página de Yelp. De esta manera podemos reemplazar todos nuestros `NaNs` con `0`s. Para ello podemos utilizar el método `.fillna()`.\n",
    "\n",
    "Rellena los valores que faltan en `df` con `0`. Después, confirme que los valores que faltan han sido rellenados con `df.isna().any()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio\n",
    "Ahora que nuestros datos están todos juntos, investiguemos algunas de las diferentes características para ver qué podría correlacionarse más con nuestra variable dependiente, la calificacion de Yelp (llamada `stars` en nuestro DataFrame). Las características con las mejores correlaciones podrían ser las más útiles para nuestro modelo de Regresión Lineal! \n",
    "\n",
    "Los DataFrames de Pandas tienen un método realmente útil, `.corr()`, que nos permite ver los coeficientes de correlación para cada par de nuestras diferentes características. Recuerde, una correlación de `0` indica que dos características no tienen relación lineal, un coeficiente de correlación de `1` indica que dos características tienen una relación lineal positiva perfecta, y un coeficiente de correlación de `-1` indica que dos características tienen una relación lineal negativa perfecta. \n",
    "\n",
    "llame `.corr()` sobre `df`. Verás que `number_funny_votes` tiene un coeficiente de correlación de `0.001320` con respecto a `stars` o clasificación de Yelp. Esta es una correlación muy débil. ¿Qué características se correlacionan mejor, tanto positiva como negativamente, con la clasificación Yelp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar mejor estas relaciones, podemos graficar ciertas características contra nuestra variable dependiente, la clasificación de Yelp. importe Matplotlib. Podemos usar el método `.scatter()` de Matplotlib para graficar cómo son estas correlaciones (añada como tercer parametro al scatter lo siguiente `alpha=0.1`)\n",
    "\n",
    "Grafique las tres características que más se correlacionan con la clasificación Yelp (`average_review_sentiment`, `average_review_length`, `average_review_age`) contra `stars`, nuestra clasificación Yelp. Luego trace una característica de baja correlación, como por ejemplo, `number_funny_votes`, contra `stars`.\n",
    "\n",
    "Nota: que es `average_review_sentiment`?, `average_review_sentiment` es la puntuación media de todos los comentarios en la página Yelp de un negocio. La puntuación de sentimiento para una revisión se calculó utilizando la herramienta de análisis de sentimiento VADER. VADER utiliza un conjunto de palabras positivas y negativas, junto con reglas gramaticales codificadas, para estimar qué tan positiva o negativa es una declaración. Las puntuaciones van de `1`, más negativas, a `+1`, más positivas, con una puntuación de `0` que indica una declaración neutral. Aunque no es perfecto, VADER hace un buen trabajo adivinando el sentimiento de los datos de texto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de datos\n",
    "Para poner nuestros datos en un modelo de Regresión Lineal, necesitamos separar nuestras características/features/columnas para modelar las clasificaciones de Yelp. \n",
    "\n",
    "De nuestro análisis de correlación vimos que las tres características con las correlaciones más fuertes para la calificación de Yelp son el `average_review_sentiment`, `average_review_length`, y `average_review_age`. \n",
    "\n",
    "Ya que queremos profundizar un poco más que usar solo el `average_review_sentiment`, que comprensiblemente tiene una correlación muy alta con la clasificación Yelp, elijamos crear nuestro primer modelo con `average_review_length` y `average_review_age` como características.\n",
    "\n",
    "Cree una nueva columna de DataFrame que contenga las columnas sobre las que queremos modelar y llamelo `features` con las columnas: `average_review_length` y `average_review_age`. Luego cree otro DataFrame llamado `ratings` que almacene el valor que queremos predecir, la clasificación Yelp o las `stars` en `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir los datos en conjuntos de entrenamiento y pruebas\n",
    "Estamos casi listos para modelar! Pero primero, necesitamos dividir nuestros datos en un conjunto de entrenamiento y un conjunto de pruebas para poder evaluar qué tan bien funciona nuestro modelo. \n",
    "\n",
    "Usaremos la función `train_test_split` de scikit-learn para hacer esta división. Esta función toma dos parámetros requeridos: los datos, o nuestras características, seguidos por nuestra variable dependiente, en nuestro caso la clasificación Yelp. Ajuste el parámetro opcional `test_size` a `0,2`. Finalmente, establezca el parámetro opcional `random_state` en 1. Esto hará que sus datos se dividan de la misma manera que los datos en nuestro código de solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear y entrenar al modelo\n",
    "Ahora que nuestros datos están divididos en conjuntos de entrenamiento y pruebas, ¡por fin podemos modelar! Importe `LinearRegression` desde el módulo `linear_model` de scikit-learn. \n",
    "\n",
    "Cree un nuevo objeto `LinearRegression` llamado `model`. El método `.fit()` ajustará nuestro modelo de Regresión Lineal a nuestros datos de entrenamiento y calculará los coeficientes para nuestras características. Llamar al método `.fit()` en el modelo con `X_train` y `y_train` como parámetros. De esta manera, nuestro modelo ya ha sido entrenado en nuestros datos de entrenamiento!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar y comprender el modelo\n",
    "Ahora podemos evaluar nuestro modelo de varias maneras. La primera forma será usando el método `.score()`, que proporciona el valor `R^2` para nuestro modelo. Recuerde, `R^2` es el coeficiente de determinación, o una medida de cuánto de la varianza en nuestra variable dependiente, la clasificación Yelp predicha, se explica por nuestras variables independientes, nuestros datos de características. \n",
    "\n",
    "Los valores de `R^2` van de `0` a `1`, con `0` indicando que el modelo creado no se ajusta a nuestros datos en absoluto, y con `1` indicando que el modelo se ajusta perfectamente a nuestros datos de características. \n",
    "\n",
    "Llame `.score()`en nuestro modelo con `X_train` y `y_train `como parámetros para calcular nuestra puntuación `R^2` de entrenamiento. Luego llame de nuevo al `score()`en el modelo con `X_test` y `y_test` como parámetros para calcular `R^2` para nuestros datos de prueba. \n",
    "\n",
    "¿Qué dicen estos valores de `R^2` sobre nuestro modelo? ¿Cree usted que estas características por sí solas son capaces de predecir eficazmente las clasificaciones de Yelp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de tanto trabajo, por fin podemos echar un vistazo a los coeficientes de nuestras diferentes características! \n",
    "\n",
    "El modelo tiene un atributo `.coef_` que es una matriz de los coeficientes de característica determinados al ajustar nuestro modelo a los datos de entrenamiento. Para que sea más fácil ver qué característica corresponde a qué coeficiente, hemos proporcionado un código en la celda que une una lista de nuestras características con los coeficientes y las ordena en orden descendente desde la más predictiva a la menos predictiva.\n",
    "\n",
    "```\n",
    "sorted(list(zip(['average_review_length','average_review_age'],model.coef_)),key = lambda x: abs(x[1]),reverse=True)\n",
    "```\n",
    "\n",
    "Copiela y peguela en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, podemos calcular las clasificaciones Yelp previstas para nuestros datos de pruebas y compararlas con sus clasificaciones Yelp reales. \n",
    "\n",
    "Nuestro modelo tiene un método `.predict()` que utiliza los coeficientes del modelo para calcular el valor de Yelp predicho. Llamar a `.predict()` en `X_test` y asignar los valores a `y_predicted`. \n",
    "\n",
    "Usa Matplotlib para trazar `y_test` vs `y_predicted`. Para un modelo de regresión lineal perfecto, esperaríamos ver los datos trazados a lo largo de la línea `y = x`, ¿Es éste el caso? Si no, ¿por qué no? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir diferentes subconjuntos de datos\n",
    "Después de evaluar el primer modelo, puede ver que `average_review_length` y `average_review_age` por sí solas no son los mejores predictores para la clasificación de Yelp. \n",
    "\n",
    "Vamos a hacer un poco más de modelado con diferentes subconjuntos de características y ver si podemos lograr un modelo más preciso! \n",
    "\n",
    "En las celdas de abajo hemos proporcionado diferentes listas de subconjuntos de características con las que modelaremos y evaluaremos. ¿Qué otros subconjuntos de características le gustaría probar? ¿Por qué crees que esos conjuntos de características son más predictivos de la clasificación Yelp que otros? Cree al menos un subconjunto más de características a partir de las cuales desea predecir las clasificaciones de Yelp. Copie y pegue los subconjuntos en la siguiente celda\n",
    "\n",
    "```\n",
    "# subset of only average review sentiment\n",
    "sentiment = ['average_review_sentiment']\n",
    "\n",
    "# subset of all features that have a response range [0,1]\n",
    "binary_features = ['alcohol?','has_bike_parking','takes_credit_cards','good_for_kids','take_reservations','has_wifi']\n",
    "\n",
    "# subset of all features that vary on a greater range than [0,1]\n",
    "numeric_features = ['review_count','price_range','average_caption_length','number_pics','average_review_age','average_review_length','average_review_sentiment','number_funny_votes','number_cool_votes','number_useful_votes','average_tip_length','number_tips','average_number_friends','average_days_on_yelp','average_number_fans','average_review_count','average_number_years_elite','weekday_checkins','weekend_checkins']\n",
    "\n",
    "# all features\n",
    "all_features = binary_features + numeric_features\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros modelos\n",
    "Ahora que tenemos listas de diferentes subconjuntos de características, podemos crear nuevos modelos a partir de ellos. Para poder comparar más fácilmente el rendimiento de estos nuevos modelos, hemos creado una función para usted llamada `model_these_features()`. \n",
    "\n",
    "Esta función replica el proceso de construcción del modelo que acaba de completar con nuestro primer modelo! Tómese un tiempo para revisar cómo funciona la función, analizándola línea por línea. Rellene los comentarios vacíos con una explicación de la tarea que el código debajo está realizando.\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "# take a list of features to model as a parameter\n",
    "def model_these_features(feature_list):\n",
    "\n",
    "    # define ratings and features, with the features limited to our chosen subset of data\n",
    "    ratings = df.loc[:,'stars']\n",
    "    features = df.loc[:,feature_list]\n",
    "\n",
    "    # perform train, test, split on the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, ratings, test_size = 0.2, random_state = 1)\n",
    "\n",
    "    # don't worry too much about these lines, just know that they allow the model to work when\n",
    "    # we model on just one feature instead of multiple features. Trust us on this one :)\n",
    "    if len(X_train.shape) < 2:\n",
    "        X_train = np.array(X_train).reshape(-1,1)\n",
    "        X_test = np.array(X_test).reshape(-1,1)\n",
    "\n",
    "    # create and fit the model to the training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # print the train and test scores\n",
    "    print('Train Score:', model.score(X_train,y_train))\n",
    "    print('Test Score:', model.score(X_test,y_test))\n",
    "\n",
    "    # print the model features and their corresponding coefficients, from most predictive to least predictive\n",
    "    print(sorted(list(zip(feature_list,model.coef_)),key = lambda x: abs(x[1]),reverse=True))\n",
    "\n",
    "    # calculate the predicted Yelp ratings from the test data\n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    # plot the actual Yelp Ratings vs the predicted Yelp ratings for the test data\n",
    "    plt.scatter(y_test,y_predicted)\n",
    "    plt.xlabel('Yelp Rating')\n",
    "    plt.ylabel('Predicted Yelp Rating')\n",
    "    plt.ylim(1,5)\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "Copielo y peguelo en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se sienta cómodo con los pasos de la función, ejecute modelos en los siguientes subconjuntos de datos utilizando `model_these_features()`:\n",
    "\n",
    "`sentiment`: sólo `average_review_sentiment`\n",
    "\n",
    "`binary_features`: todas las características que tienen un rango de respuesta `[0,1]`\n",
    "\n",
    "`numeric_features`: todas las características que varían en un rango mayor que `[0,1]`\n",
    "\n",
    "`all_features`: todas las características\n",
    "\n",
    "`feature_subset`: su propio subconjunto de características\n",
    "\n",
    "¿Cómo afecta el cambio de los conjuntos de características al valor R^2 del modelo? ¿Qué características son más importantes para predecir la clasificación Yelp en los diferentes modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debut de Danielle's Delicious Delicacies\n",
    "Ha cargado los datos, los ha limpiado, modelado y evaluado. Estás cansado, pero resplandeciente de orgullo después de todo el trabajo duro. Cierra los ojos y puedes ver claramente el día de apertura de Delicious Delicacies de Danielle con una fila de personas en la puerta. Pero, ¿cuál será su calificación de Yelp? Usemos nuestro modelo para hacer una predicción.\n",
    "\n",
    "Nuestro mejor modelo era el que utilizaba todas las funciones!!, así que volveremos a trabajar con este modelo. En la celda de abajo imprima `all_features` para obtener un recordatorio de las características con las que estamos trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la celda de abajo para agarrar todas las características y volver a entrenar a nuestro modelo en ellas.\n",
    "\n",
    "```\n",
    "features = df.loc[:,all_features]\n",
    "ratings = df.loc[:,'stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, ratings, test_size = 0.2, random_state = 1)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para darle una perspectiva de los restaurantes que ya existen, hemos proporcionado los valores medios, mínimos y máximos para cada característica/feature/columna a continuación. ¿Será Danielle's Delicious Delicacies otro restaurante promedio, o será un gigante de 5 estrellas entre las masas?\n",
    "\n",
    "```\n",
    "pd.DataFrame(list(zip(features.columns,features.describe().loc['mean'],features.describe().loc['min'],features.describe().loc['max'])),columns=['Feature','Mean','Min','Max'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en sus planes para el restaurante, cómo espera que sus clientes califiquen en su página de Yelp para cada uno de los features? llene los espacios en blanco en la matriz NumPy a continuación con sus valores deseados. \n",
    "\n",
    "El primer espacio en blanco corresponde a la característica en `index=0` en el DataFrame de arriba, `alcohol?` y el último espacio en blanco corresponde a la característica en `index=24`, `weekend_checkins`. Asegúrese de introducir `0` o `1` para todas las características binarias, y si no está seguro de qué valor poner para una característica, seleccione la media en el DataFrame de arriba. \n",
    "\n",
    "Guarde el array de numpy en una variable llamada `danielles_delicious_delicacies` y recuerde hacerle un `reshape(1, -1)`\n",
    "\n",
    "Después de ingresar los valores, ejecute la celda de predicción a continuación para recibir su calificación de Yelp! ¿Cómo va a ser el debut de Danielle Delicious Delicacies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Próximos pasos\n",
    "Usted ha construido con éxito un modelo de regresión lineal que predice la clasificación Yelp de un restaurante! Como has visto, puede ser bastante difícil predecir una calificación como ésta incluso cuando tenemos una plétora de datos. \n",
    "\n",
    "¿Qué otras preguntas le vienen a la mente cuando ve los datos que tenemos? ¿Qué ideas cree usted que podrían pronosticar de un tipo diferente de análisis? Aquí hay algunas ideas para reflexionar:\n",
    "\n",
    "- ¿Podemos predecir el tipo de cocina de un restaurante en función de los usuarios que la revisan?\n",
    "\n",
    "- ¿Qué restaurantes son similares entre sí en otros aspectos además del tipo de cocina?\n",
    "\n",
    "- ¿Existe un ambiente diferente en los restaurantes, y qué tipo de restaurantes se ajustan a estos conceptos?\n",
    "\n",
    "- ¿Cómo afecta el estatus de las redes sociales a la credibilidad y visibilidad de un restaurante?\n",
    "\n",
    "A medida que avance en el campo de la ciencia de datos, podrá crear modelos que aborden estas preguntas y muchas más. Pero mientras tanto, felicitece, ha alcanzado un gran logro!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
